{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:08.196527200Z",
     "start_time": "2024-02-18T05:53:05.514598400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\torch2.0.1\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from datasets.cifar10 import CIFAR10Loader\n",
    "from utils.io_utils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "from models.network.DDN import DDN\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from utils.explain_utils import calculate_ifc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "EXP_NAME = \"train\"\n",
    "CLS = 10\n",
    "INPUT_SHAPE = (3,32,32)\n",
    "BETA = 1e-2\n",
    "GAMMA = 1e-4\n",
    "ETA = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:08.212280800Z",
     "start_time": "2024-02-18T05:53:08.197527400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "input size torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "pipeline = transforms.Compose([transforms.ToTensor(),\n",
    "                        transforms.Resize(INPUT_SHAPE[1:], antialias=True),\n",
    "                        transforms.Normalize(mean=(0.4914,0.4822,0.4465), std=(0.2023,0.1994,0.2010))\n",
    "                        ])\n",
    "\n",
    "\n",
    "\n",
    "root = 'D:/project/Discardable-Distributed-Networks/data'\n",
    "dataLoader = CIFAR10Loader(root=root,transform=pipeline,batch_size=BATCH_SIZE)\n",
    "MODEL_PATH = f'D:/project/Discardable-Distributed-Networks/save/{EXP_NAME}/'\n",
    "create_directory_if_not_exists(MODEL_PATH)\n",
    "\n",
    "# dataLoader.generate_img(resize=(32,32))\n",
    "\n",
    "input_sample = torch.randn((1,) + INPUT_SHAPE).to(DEVICE)\n",
    "print(\"input size\",input_sample.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:09.751277800Z",
     "start_time": "2024-02-18T05:53:08.214280200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DDN_base(DDN):\n",
    "    def __init__(self, in_places):\n",
    "        super().__init__(in_places)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_vars_list = []\n",
    "        fusion_list = []\n",
    "        x = self.conv1(x)\n",
    "        for i in range(self.l):\n",
    "\n",
    "            x = self.blocks[i].drop_forward(x,1.0)\n",
    "\n",
    "            mu_vars, fusion = self.fusions[i](x['padding'])\n",
    "\n",
    "            if self.training:\n",
    "                mu_vars_list += mu_vars\n",
    "                f = dict()\n",
    "                f['feature'] = []\n",
    "                for feature in x['no_padding']:\n",
    "                    f['feature'].append(self.flatten(feature))\n",
    "                f['fusion'] = self.flatten(fusion)\n",
    "                fusion_list.append(f)\n",
    "            x = self.downsamples[i](fusion)\n",
    "\n",
    "        x = self.head(x)\n",
    "        if self.training:\n",
    "            return mu_vars_list, fusion_list, x\n",
    "        else:\n",
    "            return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:09.769579800Z",
     "start_time": "2024-02-18T05:53:09.752277700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def explain_Model(model_expand,model_base):\n",
    "    model_expand.eval()\n",
    "    model_base.eval()\n",
    "    img = cv2.imread(\"D:\\\\project\\\\Discardable-Distributed-Networks\\\\data\\\\cifar-10-batches-py\\\\val\\\\0\\\\774.png\")\n",
    "    data = pipeline(img).to(DEVICE)\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    img = img/float(255.0)\n",
    "    cv2.imshow(\"img\",img)\n",
    "    data = data.unsqueeze(0)\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    target_layers_expand = [model_expand.downsamples[1]]\n",
    "    cam_expand = GradCAM(model=model_expand, target_layers=target_layers_expand)\n",
    "\n",
    "    grayscale_cam_expand = cam_expand(input_tensor=data, targets=targets)\n",
    "    grayscale_cam_expand = grayscale_cam_expand[0, :]\n",
    "    grayscale_cam_expand = cv2.resize(grayscale_cam_expand,(256,256))\n",
    "    visualization_expand = show_cam_on_image(img, grayscale_cam_expand, use_rgb=True)\n",
    "    cv2.imshow(f\"camf expand\",visualization_expand)\n",
    "    cv2.imwrite(\"expand.png\",visualization_expand)\n",
    "\n",
    "    target_layers_base = [model_base.downsamples[1]]\n",
    "    cam_base = GradCAM(model=model_base, target_layers=target_layers_base)\n",
    "\n",
    "    grayscale_cam_base = cam_base(input_tensor=data, targets=targets)\n",
    "    grayscale_cam_base = grayscale_cam_base[0, :]\n",
    "    grayscale_cam_base = cv2.resize(grayscale_cam_base,(256,256))\n",
    "    visualization_base = show_cam_on_image(img, grayscale_cam_base, use_rgb=True)\n",
    "    cv2.imshow(f\"camf base\",visualization_base)\n",
    "    cv2.imwrite(\"base.png\",visualization_base)\n",
    "\n",
    "    ifc = calculate_ifc([torch.tensor(grayscale_cam_expand),torch.tensor(grayscale_cam_base)])[0][1]\n",
    "    print(\"1-ifc:\",1-ifc)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # ifc_data = ifc_dict['ifc']\n",
    "    # names = ifc_dict['names']\n",
    "    #\n",
    "    # fig, axs = plt.subplots(figsize=(14, 8))\n",
    "    #\n",
    "    # x = np.arange(len(names))\n",
    "    # width = 0.3\n",
    "    #\n",
    "    # bars = []\n",
    "    # for i, ifc in enumerate(ifc_data):\n",
    "    #     bar = axs.bar(x + i * width, ifc, width, label=names[i])\n",
    "    #     bars.append(bar)\n",
    "    #     for idx, val in enumerate(ifc):\n",
    "    #         axs.text(x[idx] + i * width, val + 0.01, str(round(val.item(), 2)), ha='center')\n",
    "    #\n",
    "    # axs.set_title('Accuracy Comparison for Different Models and Dropout Rates')\n",
    "    # axs.set_xlabel('Models')\n",
    "    # axs.set_ylabel('Accuracy')\n",
    "    # axs.set_xticklabels(ifc_dict['names'], rotation=45, ha='right')\n",
    "    # axs.legend()\n",
    "    #\n",
    "    # # 显示图表\n",
    "    # plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:09.782579500Z",
     "start_time": "2024-02-18T05:53:09.775581400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def explain(MODEL_NAME='DDN'):\n",
    "    model_name = os.path.join(MODEL_PATH,f'{MODEL_NAME}.ckpt')\n",
    "    model_expand = DDN(in_places=3)\n",
    "    model_expand.load_state_dict(torch.load(model_name))\n",
    "    model_expand = model_expand.to(DEVICE)\n",
    "\n",
    "    model_base = DDN_base(in_places=3)\n",
    "    model_base.load_state_dict(torch.load(model_name))\n",
    "    model_base = model_base.to(DEVICE)\n",
    "\n",
    "    explain_Model(model_expand, model_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:53:09.799580900Z",
     "start_time": "2024-02-18T05:53:09.783579500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "explain()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T07:28:27.337719600Z",
     "start_time": "2024-02-18T05:53:09.798580100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T07:28:27.352720200Z",
     "start_time": "2024-02-18T07:28:27.338719800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
